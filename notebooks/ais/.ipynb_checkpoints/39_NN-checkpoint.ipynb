{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e54d11e8-c54c-429a-8d64-a713cbbb34c1",
   "metadata": {},
   "source": [
    "https://github.com/StackAbuse/Introduction-to-GANs-with-Python-and-TensorFlow\n",
    "\n",
    "https://stackabuse.com/introduction-to-gans-with-python-and-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074b6d47-7c9e-4e07-90b3-9e2362a4aa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2875827-7c6d-4e17-89a2-441aa6375544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample z from uniform distribution\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e8ccd6-fe6b-441a-b90b-68116d066f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cae5edac-d497-438f-bc51-39982b39a034",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tf.placeholder() is not compatible with eager execution.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Declare inputs and parameters to the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Input image, foe discrminator model.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# X = tf.placeholder(tf.float32, shape=[None, 784])\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceholder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m784\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m784\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:3298\u001b[0m, in \u001b[0;36mplaceholder\u001b[0;34m(dtype, shape, name)\u001b[0m\n\u001b[1;32m   3251\u001b[0m \u001b[38;5;124;03m\"\"\"Inserts a placeholder for a tensor that will be always fed.\u001b[39;00m\n\u001b[1;32m   3252\u001b[0m \n\u001b[1;32m   3253\u001b[0m \u001b[38;5;124;03m**Important**: This tensor will produce an error if evaluated. Its value must\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3295\u001b[0m \u001b[38;5;124;03m@end_compatibility\u001b[39;00m\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m-> 3298\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.placeholder() is not compatible with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3299\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager execution.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gen_array_ops\u001b[38;5;241m.\u001b[39mplaceholder(dtype\u001b[38;5;241m=\u001b[39mdtype, shape\u001b[38;5;241m=\u001b[39mshape, name\u001b[38;5;241m=\u001b[39mname)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: tf.placeholder() is not compatible with eager execution."
     ]
    }
   ],
   "source": [
    "# Declare inputs and parameters to the model\n",
    "\n",
    "# Input image, foe discrminator model.\n",
    "# X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "X = tf.compat.v1.placeholder(tf.float32, shape=[784, 784])\n",
    "\n",
    "# Input noise for generator.\n",
    "#Z = tf.placeholder(tf.float32, shape=[None, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "039af902-c425-4086-9c0e-55cda9af306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    \n",
    "    with tf.variable_scope(\"generator\", reuse=tf.AUTO_REUSE):\n",
    "        \n",
    "        x = tf.layers.dense(z, 128, activation = tf.nn.relu)\n",
    "        x = tf.layers.dense(z, 784)\n",
    "        x = tf.nn.sigmoid(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def discriminator(x):\n",
    "    with tf.variable_scope(\"discrminator\", reuse=tf.AUTO_REUSE):\n",
    "        x = tf.layers.dense(x, 128, activation = tf.nn.relu)\n",
    "        x = tf.layers.dense(x, 1)\n",
    "        x = tf.nn.sigmoid(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55c1a3b7-7334-48a1-8342-756156337947",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m G_sample \u001b[38;5;241m=\u001b[39m generator(\u001b[43mZ\u001b[49m)\n\u001b[1;32m      2\u001b[0m D_real \u001b[38;5;241m=\u001b[39m discriminator(X)\n\u001b[1;32m      3\u001b[0m D_fake \u001b[38;5;241m=\u001b[39m discriminator(G_sample)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Z' is not defined"
     ]
    }
   ],
   "source": [
    "G_sample = generator(Z)\n",
    "D_real = discriminator(X)\n",
    "D_fake = discriminator(G_sample)\n",
    "\n",
    "D_loss = -tf.reduce_mean(tf.log(D_real) + tf.log(1. - D_fake))\n",
    "G_loss = -tf.reduce_mean(tf.log(D_fake))\n",
    "\n",
    "# Optimizers\n",
    "disc_vars = [var for var in tf.trainable_variables() if var.name.startswith(\"disc\")]\n",
    "gen_vars =  [var for var in tf.trainable_variables() if var.name.startswith(\"gen\")]\n",
    "\n",
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=disc_vars)\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=gen_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b909ef1-fa30-4c62-a317-4e0620a11b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "mb_size = 128\n",
    "\n",
    "# Dimention of input noise\n",
    "Z_dim = 100\n",
    "\n",
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('out2/'):\n",
    "    os.makedirs('out2/')\n",
    "\n",
    "i = 0\n",
    "\n",
    "for it in range(1000000):\n",
    "    \n",
    "    # Save generated images every 1000 iterations.\n",
    "    if it % 1000 == 0:\n",
    "        samples = sess.run(G_sample, feed_dict={Z: sample_Z(16, Z_dim)})\n",
    "\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('out2/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)\n",
    "        \n",
    "        \n",
    "    # Get next batch of images. Each batch has mb_size samples.\n",
    "    X_mb, _ = mnist.train.next_batch(mb_size)\n",
    "    \n",
    "    \n",
    "    # Run disciminator solver\n",
    "    _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: sample_Z(mb_size, Z_dim)})\n",
    "    \n",
    "    # Run generator solver\n",
    "    _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(mb_size, Z_dim)})\n",
    "\n",
    "    # Print loss\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('D loss: {:.4}'. format(D_loss_curr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb847268-42b4-4480-aeb5-810f4515babd",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/generative/dcgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9823ad7c-7ee6-433a-bc4d-2ea965ca9805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f900ee5c-8aed-4dfb-b158-45de84c217b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d726d6b6-71f1-44b5-bc00-6d4f3f6582f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "11501568/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "511d8830-9396-445c-9ac1-d54fd7e3f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f54dc2a-8f2f-4c6e-b976-8112ae80698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 17:00:30.329267: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-11 17:00:30.329355: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-11 17:00:30.329390: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a15c8d2a57f3): /proc/driver/nvidia/version does not exist\n",
      "2022-05-11 17:00:30.334249: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25f5bd69-6c75-404a-8abc-e004f705d7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c7000c4-518a-486a-a6ba-44e74db10a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5ae1302e20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56648e6d-d82a-47f4-a9f9-d55d5a7633e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1935ec39-49fc-42e2-8ff5-b610215cc3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00149186]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07f1f0d3-7973-4419-8d30-5309cc45ad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24035f93-307a-45d3-ab69-2898d8aa44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c72b380-2aaa-4c4b-a6a5-5d6ed2bff5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7a520af-770f-46cb-9488-17cb6bcc5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e2804da-a1a9-4100-b804-835df03b0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b54a6a7-0e79-49b8-8fdb-0487681b2fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# You will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b44e7f3-b817-4efe-b77e-0e649aa3cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
